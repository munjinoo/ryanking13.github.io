---
date: "2021-09-05T01:01:00Z"
title: 머신러닝 연구를 하면서 함정에 빠지지 않는 법 (번역)
categories:
- Development
description: 머신러닝 연구를 하면서 함정에 빠지지 않는 법
summary: 머신러닝 연구를 하면서 함정에 빠지지 않는 법
draft: True
---

> __원문:__ [*"How to avoid machine learning pitfalls: a guide for academic researchers"* (M. A. Lones)](https://arxiv.org/abs/2108.02497)

> __Note:__ 가볍게 읽으실 수 있도록 많은 부분이 축약 또는 생략되어 있습니다. <br /> 이 글이 마음에 드셨다면 원문을 꼭 읽어보시는 것을 추천드립니다.

## 들어가며

이 글은 머신러닝 연구를 막 시작한 학생들과 풋내기 연구자들에게,
머신러닝 연구를 하면서 발생하는 여러 가지 실수들을
방지하는 데에 도움을 주고자 작성되었습니다.

이 글이 다른 머신러닝 입문 강의와 다른 점은,
이 글에서 소개하는 내용은 학계에서
머신러닝 연구를 하는 사람들만을 독자로 한다는 점입니다.
바꾸어 말하면, 연구 내용을 논문으로 출판하기 위해,
실험 결과를 엄격하게 평가하고 정당하게 비교해야하는 사람들을 대상으로 합니다.

## 1. 모델을 만들기 전에 해야할 일

여러분이 새로운 연구를 시작하면,
두근대는 마음에 곧바로 모델을 학습시키고 평가하고 싶을 것입니다.

그러나 두근거림을 가라앉히세요.
여러분에게 필요한 것은 시간을 두고 신중하게 프로젝트의 목표를 점검하고,
데이터를 완전히 이해하는 작업입니다.

### 1.1. 데이터를 살펴보세요

머신러닝 연구를 한다는 것은
최종적으로 여러분의 작업을 논문 등의 형태로 발표하는게 목표일 것입니다.
이 경우 연구에 사용하는 데이터가
신뢰할 수 있는 소스에서 나왔는지,
신뢰할 수 있는 방법론을 이용해서 수집되었는지,
그리고 데이터의 퀄리티가 충분히 좋은지를 확인해야 합니다.

예를 들어,
인터넷에서 찾은 데이터를 사용한다면
그게 어디서 만든 데이터인지를 알아야 합니다.
다른 논문에서 데이터를 만들었다면,
그 논문을 살펴보고 믿을만한 기관에서 출판된 논문인지,
저자들이 데이터의 한계점이나 퀄리티에 대해서 명시해뒀는지 살펴보아야 합니다.

데이터가 여러 논문에서 이미 사용되었다고해서
그 데이터가 좋은 퀄리티일 것이라고 의심없이 믿으면 안 됩니다.
머신러닝 업계에는 *"쓰레기가 들어가면 쓰레기가 나온다"* 는 유명한 격언이 있습니다.
이는 데이터가 안 좋으면 좋은 모델이 나올 수 없음을 의미합니다.

데이터를 살펴보면서, 빠지거나 불완전한 데이터가 있는지 확인하세요.
귀찮더라도 미리 하는 것이 나중에
논문 리뷰어들에게 왜 안 좋은 데이터를 썼는지 설명하는 것보다 쉽습니다.

 ### 1.2. 모든 데이터를 보지 마세요
 
 데이터를 살펴봄으로써 얻을 수 있는 다른 이점은,
 데이터의 패턴과 같이 모델링을 할 때 인사이트를 얻을 수 있는
 여러가지 요소를 발견할 수 있다는 점입니다.
 
 그러나 이때 주의해야 할 점은 데이터로부터 얻은 정보는 반드시 
 테스트할 수 없다는 것이 중요한데, 가정을 하는 것은 좋지만 이는 학습에만 사용되어야 하며 테스트때는 사용되어서는 안된다.
 그러므로 테스트 데이터를 자세히 살펴보는 것은 삼가야한다.
 그렇지 않으면 의식적으로든 무의식적으로든
 가정을 하게 되고 이는 모델의 generality를 해친다.
 테스트 데이터의 정보가 leak되는 것이 많은 경우에 모델이 일반화되지 않는 이유다.
 
 ### 1.3. 충분한 데이터를 확보하라
 
 충분한 데이터가 없으면 모델이 일반화하기 어렵다.
 이를 사전에 판단하는 것은 어렵다. 학습을 해보아야만 알 수 있는 경우가 많은데, 
 데이터에 유용한 정보(signal)과 그렇지 않은 정보(noise)의 비율에 따라 필요한 데이터량이 달라진다
 signal이 많으면 적은 데이터로도 잘 학습할 수 있지만, 그렇지 않으면 더 많은 데이터가 필요하다.
 많은 데이터를 구할 수 없으면 (이것이 많은 연구 문야에서 문제가되는데)
 
 있는 데이터를 잘 활용할 필요가 있다. cross-validation이라거나.
 또 data augmentation 테크닉을 잘 활용해서 작은 데이터셋을 부스팅 하는 것도 방법이다.
 augmentation은 데이터의 일부만 부족할 때도 유용한데, 예를 들어 분류 문제에서 특정 클래스에 해당하는 인스턴스 수만 적은 경우다. 이를 class imbalance 문제라고 하는데 augmentation이 해법이될 수 있다.
 
 그러나 데이터가 적으면 보통 모델의 복잡도가 제한된다, 딥 뉴럴네트워크 모델은 파라미터가 많은데 
 데이터가 작으면 오버피팅 되기 쉽다.
 방법이야 어찌됐든 이를 빠르게 알아채고 적절할 전략으로 해결하는 것이 중요하다.
 
 ### 1.4. 도메인 전문가들과 소통하라
 
 도메인 전문가들은 중요하다. 그들을 여러분이 풀고자하는 문제를 이해하는데 도움을 주고 가장 적절할
 방법론과 모델을 찾는데 도움을 줄것이다.
 그리고 더 적합한 audience에 출판할 수 있도록 도움을 줄것.
 도메인 전문가의 의견을 무시하면 의미없는 문제를 풀거나, 의미있는 문제를 잘못된 방법으로 풀게될 수 있다.
 후자의 예는 의료나 금융처럼 모델의 결과를 해석하는 것이 굉장히 중요한 분야에서 완전한 블랙박스 모델을 사용해서 문제를 푸는 것.
 프로젝트를 시작할때 도메인 전문가들은 여러분이 데이터를 이해하고 유의미한 피쳐를 골라내는데 도움을 주고,
 끝날 때는 출판하는데 도움을 줄 것.
 
   ### 1.5. 많은 조사를 하라
   
   여러분은 여러분이 풀고자 하는 문제를 처음 mL로 풀고자 하는 사람이 아닐 것.
   그러므로 이미 한 것과 안 한 것을 구분하는 것이 중요.
   다른 사람이 이미 여러분이 하고자 하는 것을 했다는 것은 나쁜 일이 아님.
   아카데믹한 PROGRESS는 보통 점진적으로 일어남.
   과거의 연구는 다음 연구의 이정표가 됨.
   다른 사람이 여러분의 좋은 아이디어를 이미 출판한 것을 발견하면 좌절스러울 수도 있겠지만,
   보통은 여러가지 후속 연구를 할 수 있는 지점들을 남겨놓음.
   그들의 연구가 여러분의 연구를 정당화 시켜줄것.
   과거의 연구를 무시하는 것은 중요한 정보들을 놓칠 수 있음
   그러므로 연구 시작 전에 조사를 많이 하는 것이 중요.
   이거 늦게 하면 나중에 왜 이미 했던 것들을 또 했는지 설명하는 것이 힘들어 질 것
   
   ### 1.6. 모델이 배포되는 상황을 고려할 것
   
   ML 모델을 만드는 이유는 결국 배포하기 위한 것.
   많은 수의 아카데믹 연구들이 연구에 그치고 현실에서 쓸 수 있는 모델을 만드는데 목표를 두지 않는데.
   연구 측면에서는 괜찮을 수 있지만, 결국 최종적인 목표는 현실에서 쓸 수 있는 것을 만드는 것이 되어야 함.
   이를 고려하면 나중에 어떻게 배포할 지를 고려하는 것이 중요.
   예를 들어 리소스가 부족한 환경에 배포하는 경우, 센서나 로봇이라면 모델의 복잡도를 제한해야 할것.
   시간 제안이 있는 경우라면 (밀리초단위로 판단을 해야하는 경우),  모델을 선택하는 데에 제약이 있으 ㄹ것.
   모델이 다른 거대한 소프트웨어 시스템과 조합되어 배포될 경우도 고려,
   이러한 요소들을 굉장히 복잡하고. 최근에는 MLOps라는 이름으로 많이 연구가 되고 있음.
   
   ## How to reliably build models
   
   모델을 만드는 것은 ML 연구에서 제일 재미있는 부분 중 하나입니다.
   최신 머신러닝 프레임워크를 활용하면 온갖 종류의 기술과 여러분의 데이터를 조합해 제일 좋은 성능을 보이는 모델을 쉽게 만들 수 있죠.
   그러나 이러한 방식의 접근은 전혀 통제되지 않은 수많은 실험을 낳게되고, 왜 그런 선택을 했는지를 정당화하기가 어렵습니다.
   그러므로 모델을 만들 때에는 아주 organised manner로 해야합니다. 데이터를 올바르게 쓰고 있는지 확인하고,
   적절한 요소들을 고려해 모델을 만들어야 하죠.
   
   ### 테스트 데이터가 학습 과정에 유출되면 안됩니다.
   
   여러분이 만든 모델이 얼마나 잘 일반화되는 지를 확인하기 위한 데이터를 두는 것은 아주 중요합니다.
   흔한 실수는 이 데이터에 대한 정보가 학습 과정 또는 모델 선택 과정에 유출되는 것이죠.
   이러한 일이 발생하면, 해당 데이터는 더 이상 모델의 일반화 성능을 측정하기 위한 적절한 기준이 되지 못하고,
   이것이 많은 ml 모델들이 현실 세계의 데이터에 실패하는 흔한 이유이기도 합니다.
   테스트 데이터에서 유출될 수 있는 정보의 종류는 아주 여러가지가 있습니다.
   예를들어 데이터 준비과정에서 값의 평균과 범위를 알고 스케일링을 하는 경우가 있죠.
   이러한 정보 유출을 방지하기 위해서는 이러한 작업은 오로지 학습 데이터만을 이용해서 수행되어야 합니다.
 
  다른 흔한 예로는 데이터를 나누지 전에 feature selection을 하는 것, 서로 다른 모델의 일반화 성능을 평가하기 위해 같은 테스트 데이터를 쓰는 것 등이 있습니다. 이러한 실수를 예방하는 가장 좋은 방법은 프로젝트가 시작하자 마자
  데이터를 나누고 테스트 데이터는 오로지 마지막에 나온 한 모델의 일반화 성능을  측정하는데만 사용하는 것입니다.
  
  ### 여러가지 모델을 사용해보세요
  
  일반적으로, 어디에서나 가장 좋은 한 머신 러닝 모델이라는 것은 없습니다.
  공짜 점심은 없다는 유명한 법칙이 있듯이, 특정 모델이 모든 문제에서 뛰어날 수는 없죠.
  여러분이 할 일은 특정한 한 가지 문제를 가장 잘 풀어내는 모델을 찾는 것입니다.
  이미 좋은 퀄리티의 priori knowledge를 제공하는 연구가 있다면, 그것을 기반으로 연구를 진행하면 되겠지만,
  많은 경우에 여러분은 완전 캄캄한 어둠속에서 시작하게 될 것입니다.
  다행히도 최근의 머신러닝 라이브러리를 사용하면 여러가지 모델을 조금의 코드 수정을 통해 쉽게 바꿔가며 실험하는 것이 가능합니다. 그러므로 여러가지 다른 모델을 사용해보지 않을 이유가 없죠.
  
  ### 부적절한 모델 사용하지 않기
  
  최신 머신러닝 라이브러리들은 아주 쉽게 모델을 사용할 수 있다보니,
  종종 여러분의 데이터와는 맞지 않는 부적절한 모델을 사용하게 되는 경우가 있습니다.
  예를 들면 categorical 데이터를 입력으로 받는 모델에 numeric features를 입력한다던지 하는 것 말이지요.
  혹은 데이터간의 종속성이 없다고 가정하는 모델에 시계열 데이터를 입력하는 등의 것이 있을 수 있습니다.
  이는 특히 여러분의 연구를 출판하기 전에 반드시 확인하여야 하는 것입니다. 부적절한 모델을 사용했다가는 리뷰어들이 여러분의 연구 자체를 안좋게 볼 것.
  또 다른 예시는 불필요하게 복잡한 모델을 사용하는 것입니다.
  예를 들어, 여러분의 데이터의 수가 매우 적거나, 모델의 추론 결과에 대한 해석이 필요하다면 딥 뉴럴네트워크 모델을 사용하는 것은 적합하지 않을 것입니다.
  마지막으로 "최신" 모델이라는 것이 여러분이 그 모델의 사용을 정당화 하는 이유로 사용하지 마세요. 오래되었어도 잘 연구되고 만들어진 모델이 더 좋은 결과를 보이는 경우가 많습니다.
  
  ### 모델의 하이퍼파라미터를 최적화화세요.
  
  많은 모델들이 하이퍼파라미터를 가지고 있습니다. 
  모델의 아키텍쳐나 학습에 관계된 여러가지 설정값들 같은 것들 말이죠.
  이러한 하이퍼파라미터들은 모델의 성능에 아주 큰 영향을 주는 경우가 많고, 어디에서나 잘 들어맞는 값이 존재하는 경우도 드뭅니다.
  즉, 여러분의 특정한 데이터에 맞는 적절한 하이퍼파라미터값을 찾을 필요가 있습니다.
  이 때, 좋은 결과가 나올때까지 마냥 하이퍼파라미터를 이것저것 정성적으로 조정해보는 것이 끌릴 수 있지만,
  그렇게 하기보다는 적절한 하이퍼파라미터 최적화 전략을 사용하는 것이 더 좋습니다.
  이러한 방식이 여러분의 선택을 정당화하는 데도 더 도움을 줄 것입니다.
  대표적인 전략은 랜덤 서치, 그리드 서치 등이 있는데, 이는 하이퍼파라미터의 수가 많아지거나 모델을 학습시키는데 너무 오랜 시간이 들면 적합하지 않을 수도 있다.
  그러므로 최적의 세팅을 찾기 위해 적합한 도구를 사용하는 것이 필요할 수 있다.
  또 다른 접근은 AutoML 테크닉을 사용해서 모델 선택과 하이퍼파라미터를 함께 최적화하는것.
  
  ## 모델을 강인하게 평가하는 방법
  
  여러분의 결과를 학계에 보고하려면, valid한 결과로부터 얻어지는 유의미한 결론이 필요.
 안타깝게도 머신러닝 모델을 공정하게 평가하는 것은 쉽지 않다.
 그러므로 모델의 성능을 평가하는 데에는 아주 신중한 접근이 필요하다.
 
 ### 적절한 테스트 데이터 사용하기
 
 가장 먼저 모델의 일반화 성능을 평가할 수 있는 좋은 테스트 데이터를 사용하는 것이 중요합니다.
 학습 데이터에 모델이 좋은 성능을 보이는 것은 대체로 무의미합니다. 충분히 복잡한 모델은 학습 데이터가 가진 모든 정보를 얻을 수 있기 때문이죠, 일반화된 정보는 얻지 않은 채로.
 또한 테스트 데이터에 포함된 데이터가 적합한지를 판단하는 것이 중요합니다.
 이는 테스트 데이터와 학습 데이터가 중복되어서는 안 되고, 더 넓은 분포를 대표할 수 있어야 한다는 점을 말합니다.
 예를 들어, 사진 데이터를 분류하는 문제에서, 학습 데이터와 테스트 데이터가 둘다 야외의 햇살 좋은 날에 촬영된 것이라면
 테스트 데이터가 충분히 다양한 환경의 분포를 고려하지 못하고 있다고 할 수 있습니다.
 또한 학습 데이터와 테스트 데이터를 촬영할 때 완전히 똑같은 장비를 사용했다면, 이것도 특정 장비에 bias가 걸릴 수 있다.
 모델이 학습 장비오 관련된 요소들에 오버피팅 된다면, 다른 장비에서 촬영된 데이터에는 맞지 않을 수 있다. 그리고 이는 텟트 데이터에 대한 실험으로는 알아내는 것이 불가능하다.
 
 ### 검증 데이터 쓰기
 
 머신러닝 연구 과정에서 여러가지 모델을 학습하는 것이 아주 일반적. 각 모델의 성능 실험에서 얻어지는 정보를 다음 실험에 활용하게 됩니다.
 이때 테스트 데이터를 이 반복적인 과정에서 사용하지 않아야 합니다.
 대신 별도의 검증 데이터를 만들어서 성능 평가에 사용해야 합니다.
 검증 데이터는 학습용 데이터와는 다르면서 학습 과정에 도움이 되기 위해 사용합니다.
 테스트 데이터를 이 목적으로 사용한다면, 테스트 데이터가 학습 과정에 편입되고,
 이는 테스트 데이터가 더이상 일반화 성능을 특정하는 독립적인 데이터로 사용될 수 없음을 의미합니다.
 (여러분의 모델이 점점 테스트 데이터에 오버피팅 될 것이니까요)
 검증 데이터를 사용했을 때 얻을 수 있는 다른 이점은 early stopping 기법을 쓸 수 있다는 점입니다.
 earyly stopping이란 학습 과정에서 모델이 검증 데이터에 대해서 최고 성능을 찍고 떨어지기 시작할때,
 즉 학습 데이터에 오버피팅 되기 시작할 때
 일찍 학습을 중단함으로써 가장 좋은 모델 성능을 얻는 방법입니다.
 
 ### 모델을 여러번 평가하세요
 
 많은 머신 러닝 모델들은 불안정합니다.
 이는 여러 번 학습을 하거나, 데이터에 미묘한 수정만 가해져도 성능이 크게 차이날 수 있음을 의미합니다.
 즉 모델을 단 한번 평가했을 때 나오는 결과는 신뢰하기가 어렵고, 모델의 성능을 저평가 또는 고평가하게 될 위험이 있습니다.
 그러므로 모델을 여러번 평가하는 것이 중요합니다.
 이를 위한 방법은 여러가지인데,
 대표적으로는 서로 다른 여러 학습데이터를 이용해서 모델을 학습하는 방법이 있고 대표적으로는 Cross validation이 유명합니다.
 
 ### imbalanced 데이터에 대해서는 accurary를 사용하지 마세요
 
마지막으로, 머신러닝 모델을 평가하는 metric를 정할때에 유의해야할 점입니다.
예를 들어, 분류 문제를 푸는 모델을 평가할 때, 가장 흔히 사용되는 것은 정확도 메트릭,
전체 데이터 중에서 올바르게 분류된 데이터의 비율을 가지고 모델을 평가하는 것.
이러한 방식은 클래스별 데이터 개수가 균형잡혀 있다면 괜찮은데,
균협잡혀있지 않다면 문제가 된다.
예를 들어 데이터의 90%가 한 클래스고, 10%만 다른 클래스인 binary 클래스 문제라면,
분류기가 모든 데이터를 한 클래스로 추론하더라도 정확도는 90%가 나올것.
정확도는 높지만 이 분류기는 아무 쓸모가 없다.
이런 경우에는 Cohen's kappa coefficient나 Matthews Correlation Coefficient같은 다른 클래스 불균형에
무관한 메트릭을 사용해야 합니다.
 
## 모델을 공저하게 비교하는 방법 

 모델을 비교하는 것은 학술 연구의 기본입니다. 그렇지만 공정하게 모델을 비교하는 것은 매우 어려운 일이기도합니다.
 만약 모델을 공정하게 비교하지 못하고 논문을 출판한다면,
 나중에 여러분의 논문을 살펴볼 다른 연구자들에게까지 악영향을 끼칠 수 있습니다.
 그러므로 모델을 ~ 하는 것은 중요.
 
 ### 단순히 더 큰 숫자가 더 좋은 모델을 의미하지 않습니다.
 
 많은 논문들이 "기본 연구는 정확도가 94%였는데 우리는 95%니까 우리 방법이 더 좋다"라는 식으로 얘기하고는 합니다.
 그러나 단순히 높은 숫자가 더 좋은 모델을 의미하지는 않습니다.
 예를 들어, 모델이 같은 데이터를 사용했더라도 학습 데이터와 평가 데이터를 나누는 방식이 달랐을 수 있습니다. 이는 결과에 분명히 영향을 주는 요인.
 서로 다른 데이터를 사용했다면 당연히 성능에 큰 차이가 있을 것.
 또 다른 이유로는 하이퍼파라미터의 최적화 정도에 차이가 있을 수 있다. 한 모델은 기본 세팅을 사용했고,
 다른 모델은 철저하게 최적화된 하이퍼파라미터를 사용했다면 성능에 차이가 있을 수밖에 없다.
 이러한 여러가지 이유로 논문을 출판할때 사용하는 숫자들에는 굉장히 신중을 기울여야한다.
 완전히 평등한 평가를 내리기 위해선, 두 모델을 완전히 새로 구현하고,
 둘 모두 같은 수준에서 최적화하고, 여러번의 평가를 수행해야한다.
 그리고 통계적으로 성능의 차이가 유의미한지를 분석해야한다.
 
 ### 모델을 비교할때는 통계학적 검증을 할것
 
 여러분이 만든 모델이 다른 모델보다 우수하다고 얘기하려면, 통계학적 검증이 좋은 도구가 될것.
 ~
 
 ### 커뮤니티 벤치마크를 신뢰하지 말것
 
 특정 도메인에서 연구를 수행하다보면 새 모델을 평가하기 위해 사용되는 벤치마크 데이터셋이 있는 경우가 많습니다.
 이는 모두가 같은 데이터를 사용함으로서 모델의 성능을 투명하게 비교하기 위한 것입니다.
 그러나 이 방식은 몇가지 한계점이 있습니다.
 먼저 테스트 데이터에 대한 접근이 허용되기 때문에,
 다른 사람들이 테스트 데이터에 대한 정보를 학습 과정에 사용하였는지에 대한 여부를 알 수가 없습니다. 테스트 데이터를 학습에 사용하게 되면 결과가 매우 이상적으로 나오게 되죠.
또 다른 미묘한 문제는, 모두가 테스트 셋을 단 한번만 사용해서 모델을 평가했더라도,
이러한 연구가 커뮤니티에 의해 모이고 결과를 비교하다보면, 결국 테스트 데이터에 오버피팅된 모델이 좋은 모델로 평가받게 됩니다.
이러한 이유로 벤치마크 데이터로부터 얻은 결과를 사용할 때는 매우 신중해야 하고, 약간의 성능 향상을 침소봉대하여 해석하면 안됩니다.

### 모델의 조합을 고려해볼 것

이 챕터는 모델을 비교하는 내용을 다루고 있지만, 명심해야 할것은 머신러닝이 반드시 서로 다른 모델 중 하나를 골라야 하는 것은 아닙니다.
종종 여러 모델을 조합하는 것이 더 좋
 

## 결과를 보고하는 방법

연구의 목표는 혼자 만족하는 것이 아니라, 세상의 지식에 기여하는 것입니다.
지식에 기여하기 위해서는 여러분의 전체 연구에 대한 완전한 청사진. 여러분이 한 것과 하지 않은 것을 보여주어야 합니다.
머신러닝은 보통 trade-off가 있습니다. 특정 모델이 다른 모델에 비해 모든 점에서 우수한 경우는 아주 드뭅니다.
그러므로 여러분은 결과를 보고하고 결론을 제시할 때에 여러가지 요소들을 고려하여야 합니다.

### 결과를 투명하게 공개하세요

결과에 대해 얘기할 때 가장 중요한 점은,
언제나 여러분이 한 것과 발견한 것에 대해 투명하게 알려야한다는 점입니다.
이는 다른 사람들이 여러분의 연구를 토대로 다른 연구를 하기 쉽게 만들어줍니다.

예를 들어, 여러분이 연구에 사용한 모델을 접근가능한 형태로 공개하는 것이 좋습니다.
여러분이 실험을 수행하기 위해 사용한 스크립트가 있다면,
결과를 공개할 때 그것을 함께 공개하세요.
이는 여러분의 연구 결과에 대한 신뢰성을 높여줄 것이고,
다른 연구자들이 모델을 비교할 때
여러분의 모델을 바닥부터 다시 구현하게 되는 수고도 덜어줄 것입니다.

또 여러분이 결과물을 공유하는 것을 전제로 하고 연구를 한다면,
모든 것에 더 조심스러워질 것입니다.
문서화도 더 열심히 할 것이고,
클린 코드를 작성하기 위해 노력하겠죠.
이는 여러분 자신에게도 도움이 되는 일입니다.

### 여러가지 방법으로 성능을 측정하세요

모델을 엄격하게 평가하고 비교하기 위해서 사용되는 대표적인 방법은
여러 개의 데이터를 사용하는 것입니다.
이는 개별 데이터가 가지고 있는 한계점을 극복함으로써
모델의 일반화 성능을 평가하는 데에 도움을 줍니다.

각각의 데이터에 대해서도 여러 개의 평가 지표를 사용하면 더 좋습니다.
각각의 지표는 결과를 서로 다른 측면에서 해석할 수 있게 해주고,
이는 여러분의 연구의 투명성을 더해줄 것입니다.

예를 들어, 정확도 지표를 사용한다면,
클래스 불균형에 대해서 덜 민감한 지표를 추가로 사용하면 좋습니다.
혹은, 모델의 오류 정도를 측정할 때,
정밀도(precision), 재현율(recall)과 같은 부분적인 지표를 사용한다면,
오류에 대한 전체적인 정보를 알 수 있는 지표를 더해주면 좋습니다.

### 데이터를 넘어선 일반화를 하지 마세요

연구에서 나온 결과를 바탕으로 잘못된 결론을 내지 않는 것도 중요합니다.
잘못된 결론은 여러분의 연구의 가치를 떨어트릴 뿐만 아니라,
다른 연구자들까지 길을 잃게 만들 수 있습니다.

이 부분에서 발생하는 대표적인 실수는
연구 과정에서 학습하고 평가한 데이터로부터는
얻을 수 없는 일반화된 결론을 내는 것입니다.
예를 들어, 모델이 한 데이터셋에 대해 좋은 성능을 보인다고 해도,
다른 데이터에 대해 좋은 성능을 보인다고는 말하지 못합니다.
여러 데이터 셋을 사용해서 검증한다면 더 단단한 결과를 얻을 수 있지만,
그래도 이것이 모든 경우에 대해 일반화된 결론이라고는 말할 수 없습니다.
데이터를 샘플링하는 과정에서 충분히 현실 세계를 반영하지 못했을 수도 있고,
서로 다른 데이터간에 겹침이 있을 수도 있습니다.
혹은 데이터의 퀄리티 자체가 떨어질 수도 있겠죠.

그러므로, 여러분의 결과를 확대해석해서는 안 됩니다.

## 결론

이 글이 머신러닝 연구를 갓 시작한 여러분이
알아야 할 모든 것을 알려주지는 않습니다.
일부 내용은 틀렸거나, 논쟁의 여지가 있기도 할 것입니다.

그러나 이것이 연구의 본질입니다.
많은 머신러닝 이론들은 실전에서 충분히 검증되지 않았고,
연구자들은 최선의 방법이 무엇인지 늘 논쟁합니다. 오늘 맞았던 것이 내일은 틀릴 수 있습니다.
그러므로 연구를 하는 여러분에게 바라는 것은 다음과 같습니다.

늘 열린 마음을 가지세요. 발전하는 최신 연구 내용을 따라잡으려고 노력하고, 여러분이 모르는 모든 것들을 받아들일 수 있는 겸손합을 가지세요.
